{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs and RNNs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yala/introML_chem/blob/master/lab3/cnn_and_rnn_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA8LLAO9dchw",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to CNNs and RNNs in PyTorch\n",
        "In this tutorial, we'll take you through developing convolutional neural networks (CNNs) and recurrent neural networks (RNNs) in PyTorch to classify beer reviews.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcCj4gBWdFeI",
        "colab_type": "text"
      },
      "source": [
        "# Preliminaries\n",
        "\n",
        "The next few sections will set up the necessary components of the tutorial, including:\n",
        "\n",
        "\n",
        "1.   Installing PyTorch\n",
        "2.   Importing dependencies\n",
        "3.   Downloading and processing data\n",
        "4.   Defining training and evaluation procedures\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg2T9UsXctbP",
        "colab_type": "text"
      },
      "source": [
        "## Download PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT_jLzv8do9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "accelerator = 'cu100' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "print(f'Platform = {platform}, Accelerator = {accelerator}')\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl\n",
        "!pip install -q torchvision\n",
        "\n",
        "import torch\n",
        "print(f'Torch version = {torch.__version__}')\n",
        "print(f'Cuda available = {torch.cuda.is_available()}')\n",
        "print(f'Cuda version = {torch.version.cuda}')\n",
        "print(f'Cuda devices = {torch.cuda.get_device_name(0)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7uKFRTBczh9",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcLJrU16dch0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7mgPaxPc1vx",
        "colab_type": "text"
      },
      "source": [
        "## Download and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMJfz2f-JC9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install wget\n",
        "!wget https://raw.githubusercontent.com/yala/MLCodeLab/master/lab1/data/beer/overall_train.p\n",
        "!wget https://raw.githubusercontent.com/yala/MLCodeLab/master/lab1/data/beer/overall_dev.p\n",
        "!wget https://raw.githubusercontent.com/yala/MLCodeLab/master/lab1/data/beer/overall_test.p\n",
        "\n",
        "train_path = \"overall_train.p\"\n",
        "dev_path   = \"overall_dev.p\"\n",
        "test_path  = \"overall_test.p\"\n",
        "\n",
        "train_set =  pickle.load(open(train_path, 'rb'))\n",
        "dev_set =  pickle.load(open(dev_path, 'rb'))\n",
        "test_set =  pickle.load(open(test_path, 'rb'))\n",
        "\n",
        "def preprocess_data(data):\n",
        "    for indx, sample in enumerate(data):\n",
        "        text, label = sample['text'], sample['y']\n",
        "        text = re.sub('\\W+', ' ', text).lower().strip()\n",
        "        data[indx] = text, label\n",
        "    return data\n",
        "\n",
        "train_set = preprocess_data(train_set)\n",
        "dev_set = preprocess_data(dev_set)\n",
        "test_set =  preprocess_data(test_set)\n",
        "\n",
        "print(f'Num Train = {len(train_set):,}')\n",
        "print(f'Num Dev   = {len(dev_set):,}')\n",
        "print(f'Num Test  = {len(test_set):,}')\n",
        "print()\n",
        "\n",
        "trainText = [t[0] for t in train_set]\n",
        "trainY = [t[1] for t in train_set]\n",
        "\n",
        "devText = [t[0] for t in dev_set]\n",
        "devY = [t[1] for t in dev_set]\n",
        "\n",
        "testText = [t[0] for t in test_set]\n",
        "testY = [t[1] for t in test_set]\n",
        "\n",
        "print('Train class balance')\n",
        "y_count = Counter(trainY)\n",
        "for y in sorted(y_count.keys()):\n",
        "    print(f'{y} = {100. * y_count[y] / len(trainY):.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_nrd1cJc_JM",
        "colab_type": "text"
      },
      "source": [
        "## Define Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4smEQXOddciA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BeerReviewDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "      self.X, self.Y = X, Y\n",
        "      assert len(X) == len(Y)\n",
        "\n",
        "    def __len__(self):\n",
        "       return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "      return np.array(self.X[i]), self.Y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9hvStGzdcjC",
        "colab_type": "text"
      },
      "source": [
        "## Define Training Procedure\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Ht1mhhdcjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training settings\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "lr = 1e-3\n",
        "use_cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxIj0eWsdcjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, optimizer, epoch):\n",
        "    model.train() # Set the nn.Module to train mode. \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    num_samples = len(train_loader.dataset)\n",
        "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):  #1) get batch\n",
        "        # Move to cuda\n",
        "        if next(model.parameters()).is_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "      \n",
        "        # Reset gradient data to 0\n",
        "        optimizer.zero_grad()\n",
        "        # Get prediction for batch\n",
        "        output = model(data)\n",
        "        # 2) Compute loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        # 3) Do backprop\n",
        "        loss.backward()\n",
        "        # 4) Update model\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Do book-keeping to track accuracy and avg loss\n",
        "        pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total_loss += loss.detach()  # Don't keep computation graph \n",
        "\n",
        "    print(f'Train Epoch: {epoch} \\t'\n",
        "          f'Loss: {total_loss / num_samples:.4f}, '\n",
        "          f'Accuracy: {correct}/{num_samples} ({100. * correct / num_samples:.0f}%)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGZnlI58dcjN",
        "colab_type": "text"
      },
      "source": [
        "## Define Evaluation Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPzqSuY3dcjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(model, test_loader, name):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        # Move to cuda\n",
        "        if next(model.parameters()).is_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        \n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\n{name} set: '\n",
        "          f'Average loss: {test_loss:.4f}, '\n",
        "          f'Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pmcvQDx7d02",
        "colab_type": "text"
      },
      "source": [
        "## Define Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPlnEEUq7Z4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def param_count(model):\n",
        "    return sum(param.numel() for param in model.parameters() if param.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY4bFzk8fx39",
        "colab_type": "text"
      },
      "source": [
        "# Review: Bag of Words + MLP\n",
        "\n",
        "In lab 2, you classified beer reviews by first featurizing the text using bag-of-words features (i.e. `CountVectorizer`) and using a multi-layer perceptrion model (aka a basic feed-forward neural network).\n",
        "\n",
        "Let's review how we did this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_wAxoI-fnNL",
        "colab_type": "text"
      },
      "source": [
        "## Extract Bag-of-Words Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3afOUVIfpZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set parameters for CountVectorizer\n",
        "min_df = 5\n",
        "max_features = 1000\n",
        "countVec = CountVectorizer(min_df=min_df, max_features=max_features)\n",
        "\n",
        "# Learn vocabulary from train set\n",
        "countVec.fit(trainText)\n",
        "\n",
        "# Transform list of review to matrix of bag-of-word vectors\n",
        "trainX = countVec.transform(trainText).toarray()\n",
        "devX = countVec.transform(devText).toarray()\n",
        "testX = countVec.transform(testText).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkJkoLjlfp61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to Dataset\n",
        "train = BeerReviewDataset(trainX, trainY)\n",
        "dev = BeerReviewDataset(devX, devY)\n",
        "test = BeerReviewDataset(testX, testY)\n",
        "\n",
        "# Convert to DataLoader\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLJmGLCyfe6e",
        "colab_type": "text"
      },
      "source": [
        "## Define MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bW4rNKnffF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, output_size=3):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.fc3 = nn.Linear(200, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        hidden = F.relu(self.fc1(x))\n",
        "        hidden = F.relu(self.fc2(hidden))\n",
        "        logit = self.fc3(hidden)\n",
        "        return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x59SjJiIiIHP",
        "colab_type": "text"
      },
      "source": [
        "## Build MLP and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdSA9yfNiLNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLP(input_size=max_features)\n",
        "\n",
        "print(model)\n",
        "print(f'Number of parameters = {param_count(model):,}')\n",
        "\n",
        "# Move to cuda\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp9H5tWEdcjR",
        "colab_type": "text"
      },
      "source": [
        "## Train MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVpU_N0idcjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(model, train_loader, optimizer, epoch)\n",
        "    eval_epoch(model,  dev_loader, \"Dev\")\n",
        "    print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCp1o42lhSF3",
        "colab_type": "text"
      },
      "source": [
        "## Test MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyrUNrRghTRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_epoch(model,  test_loader, \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGQFSGYPpU2t",
        "colab_type": "text"
      },
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joxIzGLVqacE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download pre-trained embeddings\n",
        "!wget https://github.com/yala/introML_chem/raw/master/lab1/data/beer/words.p\n",
        "!wget https://github.com/yala/introML_chem/raw/master/lab1/data/beer/embeddings.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOLAuhxWyBwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load embeddings\n",
        "with open('words.p', 'rb') as f:\n",
        "    words = pickle.load(f)\n",
        "\n",
        "embeddings = np.load('embeddings.npz')['features']\n",
        "\n",
        "word_to_embedding = {word: embedding for word, embedding in zip(words, embeddings)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNW3uUOh7yHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Vocab size = {len(word_to_embedding):,}')\n",
        "\n",
        "print(f'Embedding of \"good\" = {word_to_embedding[\"good\"][:5]}')\n",
        "print(f'Embedding of \"bad\" = {word_to_embedding[\"bad\"][:5]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEgwodfayJfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map words to embeddings\n",
        "trainX = [[word_to_embedding[word] for word in text.split()] for text in trainText]\n",
        "devX =   [[word_to_embedding[word] for word in text.split()] for text in devText]\n",
        "testX =  [[word_to_embedding[word] for word in text.split()] for text in testText]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1K4Hg5DyimQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add padding\n",
        "max_train_len = max(len(seq) for seq in trainX)\n",
        "max_dev_len = max(len(seq) for seq in devX)\n",
        "max_test_len = max(len(seq) for seq in testX)\n",
        "\n",
        "pad = np.zeros(300)\n",
        "\n",
        "trainX = [[pad] * (max_train_len - len(seq)) + seq for seq in trainX]\n",
        "devX =   [[pad] * (max_train_len - len(seq)) + seq for seq in devX]\n",
        "testX =  [[pad] * (max_train_len - len(seq)) + seq for seq in testX]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qkAAPU60onl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to Dataset\n",
        "train = BeerReviewDataset(trainX, trainY)\n",
        "dev = BeerReviewDataset(devX, devY)\n",
        "test = BeerReviewDataset(testX, testY)\n",
        "\n",
        "# Convert to DataLoader\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnsfujvesrvU",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY_yh_IPA3hK",
        "colab_type": "text"
      },
      "source": [
        "## Define RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdLyh493swKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, embedding_dim=300, hidden_size=300, output_size=3):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        o, h = self.rnn(x)  # batch_size x seq_length x hidden_size\n",
        "        x, _ = torch.max(o, dim=1)    # batch_size x hidden_size\n",
        "#         x = h[-1]           # batch_size x hidden_size\n",
        "        x = self.output(x)  # batch_size x output_size\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOxa8rZCA446",
        "colab_type": "text"
      },
      "source": [
        "## Build RNN and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTw0eOMW0nR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN()\n",
        "\n",
        "print(model)\n",
        "print(f'Number of parameters = {param_count(model):,}')\n",
        "\n",
        "# Move to cuda\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    \n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, momentum=momentum) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaDSVZMXA7zO",
        "colab_type": "text"
      },
      "source": [
        "## Train RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUR9k6471fFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(model, train_loader, optimizer, epoch)\n",
        "    eval_epoch(model,  dev_loader, \"Dev\")\n",
        "    print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAOPc283A9t2",
        "colab_type": "text"
      },
      "source": [
        "## Test RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvS5w0e91fbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_epoch(model,  test_loader, \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sOI-H2e7sUi",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubU9eP8bBBFb",
        "colab_type": "text"
      },
      "source": [
        "## Define CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klUA9Ugi7u5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim=300, kernel_size=5, output_size=3):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=100, kernel_size=kernel_size)\n",
        "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=50, kernel_size=kernel_size)\n",
        "        self.conv3 = nn.Conv1d(in_channels=50, out_channels=10, kernel_size=kernel_size)\n",
        "        self.output = nn.Linear(10, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=kernel_size)\n",
        "        \n",
        "    def forward(self, x):  # batch_size x seq_length x embedding_dim\n",
        "        x = x.float()\n",
        "        x = x.permute(0, 2, 1)  # batch_size x embedding_dim x seq_length\n",
        "        \n",
        "        # Conv1\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        # Conv2\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Conv3\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        # Global max pooling\n",
        "        x = x.max(dim=-1)[0]  # batch_size x hidden_size\n",
        "\n",
        "        # Output linear layer\n",
        "        x = self.output(x)  # batch_size x output_size\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuaRaqdtBCrM",
        "colab_type": "text"
      },
      "source": [
        "## Build CNN and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD95lEXmAmGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN()\n",
        "\n",
        "print(model)\n",
        "print(f'Number of parameters = {param_count(model):,}')\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWwArpwcBEeo",
        "colab_type": "text"
      },
      "source": [
        "## Train CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNN7Zrr2Ap9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(model, train_loader, optimizer, epoch)\n",
        "    eval_epoch(model,  dev_loader, \"Dev\")\n",
        "    print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wROoo34BGBj",
        "colab_type": "text"
      },
      "source": [
        "## Test CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxZmibBj-GDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_epoch(model,  test_loader, \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}