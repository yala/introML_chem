{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_and_rnn_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yala/introML_chem/blob/master/lab3/cnn_and_rnn_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA8LLAO9dchw",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to CNNs and RNNs in PyTorch\n",
        "In this tutorial, we'll take you through developing convolutional neural networks (CNNs) and recurrent neural networks (RNNs) in PyTorch to classify beer reviews.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcCj4gBWdFeI",
        "colab_type": "text"
      },
      "source": [
        "# Preliminaries\n",
        "\n",
        "The next few sections will set up the necessary components of the tutorial, including:\n",
        "\n",
        "\n",
        "1.   Installing PyTorch\n",
        "2.   Importing dependencies\n",
        "3.   Downloading and processing data\n",
        "4.   Defining training and evaluation procedures\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg2T9UsXctbP",
        "colab_type": "text"
      },
      "source": [
        "## Download PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT_jLzv8do9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "accelerator = 'cu100' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "print(f'Platform = {platform}, Accelerator = {accelerator}')\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.1.0-{platform}-linux_x86_64.whl\n",
        "!pip install -q torchvision\n",
        "\n",
        "import torch\n",
        "print(f'Torch version = {torch.__version__}')\n",
        "print(f'Cuda available = {torch.cuda.is_available()}')\n",
        "print(f'Cuda version = {torch.version.cuda}')\n",
        "print(f'Cuda devices = {torch.cuda.get_device_name(0)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7uKFRTBczh9",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcLJrU16dch0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7mgPaxPc1vx",
        "colab_type": "text"
      },
      "source": [
        "## Download and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMJfz2f-JC9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install wget\n",
        "!wget https://raw.githubusercontent.com/yala/MLCodeLab/master/lab1/data/beer/overall_train.p\n",
        "!wget https://raw.githubusercontent.com/yala/MLCodeLab/master/lab1/data/beer/overall_dev.p\n",
        "!wget https://raw.githubusercontent.com/yala/MLCodeLab/master/lab1/data/beer/overall_test.p\n",
        "\n",
        "train_path = \"overall_train.p\"\n",
        "dev_path   = \"overall_dev.p\"\n",
        "test_path  = \"overall_test.p\"\n",
        "\n",
        "train_set =  pickle.load(open(train_path, 'rb'))\n",
        "dev_set =  pickle.load(open(dev_path, 'rb'))\n",
        "test_set =  pickle.load(open(test_path, 'rb'))\n",
        "\n",
        "def preprocess_data(data):\n",
        "    for indx, sample in enumerate(data):\n",
        "        text, label = sample['text'], sample['y']\n",
        "        text = re.sub('\\W+', ' ', text).lower().strip()\n",
        "        data[indx] = text, label\n",
        "    return data\n",
        "\n",
        "train_set = preprocess_data(train_set)\n",
        "dev_set = preprocess_data(dev_set)\n",
        "test_set =  preprocess_data(test_set)\n",
        "\n",
        "print(f'Num Train = {len(train_set):,}')\n",
        "print(f'Num Dev   = {len(dev_set):,}')\n",
        "print(f'Num Test  = {len(test_set):,}')\n",
        "print()\n",
        "\n",
        "trainText = [t[0] for t in train_set]\n",
        "trainY = [t[1] for t in train_set]\n",
        "\n",
        "devText = [t[0] for t in dev_set]\n",
        "devY = [t[1] for t in dev_set]\n",
        "\n",
        "testText = [t[0] for t in test_set]\n",
        "testY = [t[1] for t in test_set]\n",
        "\n",
        "print('Train class balance')\n",
        "y_count = Counter(trainY)\n",
        "for y in sorted(y_count.keys()):\n",
        "    print(f'{y} = {100. * y_count[y] / len(trainY):.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_nrd1cJc_JM",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4smEQXOddciA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BeerReviewDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "      self.X, self.Y = X, Y\n",
        "      assert len(X) == len(Y)\n",
        "\n",
        "    def __len__(self):\n",
        "       return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "      return np.array(self.X[i]), self.Y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9hvStGzdcjC",
        "colab_type": "text"
      },
      "source": [
        "## Model and Training Settings\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Ht1mhhdcjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 10\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-4\n",
        "max_len = 150\n",
        "embedding_size = 100\n",
        "hidden_size = 100\n",
        "output_size = 3\n",
        "dropout = 0.6\n",
        "use_cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz35WFTOPDFo",
        "colab_type": "text"
      },
      "source": [
        "## Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxIj0eWsdcjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, optimizer, epoch):\n",
        "    model.train() # Set the nn.Module to train mode. \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    num_samples = len(train_loader.dataset)\n",
        "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):  #1) get batch\n",
        "        # Move to cuda\n",
        "        if next(model.parameters()).is_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "      \n",
        "        # Reset gradient data to 0\n",
        "        optimizer.zero_grad()\n",
        "        # Get prediction for batch\n",
        "        output = model(data)\n",
        "        # 2) Compute loss\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        # 3) Do backprop\n",
        "        loss.backward()\n",
        "        # 4) Update model\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Do book-keeping to track accuracy and avg loss\n",
        "        pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total_loss += loss.detach()  # Don't keep computation graph \n",
        "\n",
        "    print(f'Train Epoch: {epoch} \\t'\n",
        "          f'Loss: {total_loss / num_samples:.4f}, '\n",
        "          f'Accuracy: {correct}/{num_samples} ({100. * correct / num_samples:.0f}%)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGZnlI58dcjN",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPzqSuY3dcjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(model, test_loader, name):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        # Move to cuda\n",
        "        if next(model.parameters()).is_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        \n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\n{name} set: '\n",
        "          f'Average loss: {test_loss:.4f}, '\n",
        "          f'Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pmcvQDx7d02",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPlnEEUq7Z4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def param_count(model):\n",
        "    return sum(param.numel() for param in model.parameters() if param.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGQFSGYPpU2t",
        "colab_type": "text"
      },
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFkRfCqiROvR",
        "colab_type": "text"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOLAuhxWyBwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Demo embedding\n",
        "embed = nn.Embedding(10, 5)\n",
        "print(embed(torch.LongTensor([0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUt7IN02RJvc",
        "colab_type": "text"
      },
      "source": [
        "## Define Vocab and Word-to-Index Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT93tF8iL1hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define vocab\n",
        "vocab = {word for text in trainText for word in text.split()}\n",
        "\n",
        "# Create word to index mapping\n",
        "padding_idx = 0\n",
        "unk_index = 1\n",
        "word_to_index = {word: index + 2 for index, word in enumerate(vocab)}\n",
        "vocab_size = len(word_to_index) + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDCNl7nKRHjt",
        "colab_type": "text"
      },
      "source": [
        "## Map Words to Indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEgwodfayJfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map words to indices\n",
        "trainX = [[word_to_index.get(word, unk_index) for word in text.split()] for text in trainText]\n",
        "devX =   [[word_to_index.get(word, unk_index) for word in text.split()] for text in devText]\n",
        "testX =  [[word_to_index.get(word, unk_index) for word in text.split()] for text in testText]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_OPFDOzQ8eX",
        "colab_type": "text"
      },
      "source": [
        "## Add Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1K4Hg5DyimQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in trainX]\n",
        "devX =   [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in devX]\n",
        "testX =  [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in testX]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZLu0JzjQ2LF",
        "colab_type": "text"
      },
      "source": [
        "## Build Dataset/DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qkAAPU60onl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Dataset\n",
        "train = BeerReviewDataset(trainX, trainY)\n",
        "dev = BeerReviewDataset(devX, devY)\n",
        "test = BeerReviewDataset(testX, testY)\n",
        "\n",
        "# Build DataLoader\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfXkqNFyqBsI",
        "colab_type": "text"
      },
      "source": [
        "# Multi-Layer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNQEIUKGqLM4",
        "colab_type": "text"
      },
      "source": [
        "## Define MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOD5dOZEqBAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout):\n",
        "        super(MLP, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
        "        self.fc1 = nn.Linear(embedding_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):  # batch_size x seq_length\n",
        "        # Embed\n",
        "        x = self.embed(x)  # batch_size x seq_length x embedding_size\n",
        "        \n",
        "        # Sum embeddings\n",
        "        x = x.sum(dim=1)  # batch_size x embedding_size\n",
        "        \n",
        "        # MLP\n",
        "        hidden = self.dropout(F.relu(self.fc1(x)))  # batch_size x hidden_size\n",
        "        hidden = self.dropout(F.relu(self.fc2(hidden)))  # batch_size x hidden_size\n",
        "        logit = self.fc3(hidden)  # batch_size x output_size\n",
        "        \n",
        "        return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDTl_YiUqSMK",
        "colab_type": "text"
      },
      "source": [
        "## Build MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osUGOQsvqUzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLP(vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout)\n",
        "\n",
        "print(model)\n",
        "print(f'Number of parameters = {param_count(model):,}')\n",
        "\n",
        "# Move to cuda\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCdqhdnVqV5k",
        "colab_type": "text"
      },
      "source": [
        "## Train MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXt9Oxz-qWzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(model, train_loader, optimizer, epoch)\n",
        "    eval_epoch(model,  dev_loader, \"Dev\")\n",
        "    print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE7LcxEPqW69",
        "colab_type": "text"
      },
      "source": [
        "## Test MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRTfwoZHqX5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_epoch(model,  test_loader, \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnsfujvesrvU",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY_yh_IPA3hK",
        "colab_type": "text"
      },
      "source": [
        "## Define RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdLyh493swKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=embedding_size,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):  # batch_size x seq_length\n",
        "        # Embed\n",
        "        x = self.embed(x)  # batch_size x seq_length x embedding_size\n",
        "      \n",
        "        # Run RNN\n",
        "        o, _ = self.rnn(x)  # batch_size x seq_length x hidden_size\n",
        "        \n",
        "        # Dropout\n",
        "        o = self.dropout(o)  # batch_size x seq_length x hidden_size\n",
        "        \n",
        "        # Max pooling across sequence\n",
        "        o, _ = torch.max(o, dim=1)    # batch_size x hidden_size\n",
        "        \n",
        "        # Output layer\n",
        "        logit = self.output(o)  # batch_size x output_size\n",
        "        \n",
        "        return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOxa8rZCA446",
        "colab_type": "text"
      },
      "source": [
        "## Build RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTw0eOMW0nR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout)\n",
        "\n",
        "print(model)\n",
        "print(f'Number of parameters = {param_count(model):,}')\n",
        "\n",
        "# Move to cuda\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    \n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaDSVZMXA7zO",
        "colab_type": "text"
      },
      "source": [
        "## Train RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUR9k6471fFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(model, train_loader, optimizer, epoch)\n",
        "    eval_epoch(model,  dev_loader, \"Dev\")\n",
        "    print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAOPc283A9t2",
        "colab_type": "text"
      },
      "source": [
        "## Test RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvS5w0e91fbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_epoch(model,  test_loader, \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sOI-H2e7sUi",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubU9eP8bBBFb",
        "colab_type": "text"
      },
      "source": [
        "## Define CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klUA9Ugi7u5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout):\n",
        "        super(CNN, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
        "        self.conv1 = nn.Conv1d(in_channels=embedding_size, out_channels=hidden_size, kernel_size=3, padding=0)\n",
        "        self.conv2 = nn.Conv1d(in_channels=embedding_size, out_channels=hidden_size, kernel_size=5, padding=1)\n",
        "        self.conv3 = nn.Conv1d(in_channels=embedding_size, out_channels=hidden_size, kernel_size=7, padding=2)\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):  # batch_size x seq_length\n",
        "        # Embed\n",
        "        x = self.embed(x)  # batch_size x seq_length x embedding_size\n",
        "      \n",
        "        # Permute dimensions\n",
        "        x = x.permute(0, 2, 1)  # batch_size x embedding_size x seq_length\n",
        "        \n",
        "        # Convolutional layers\n",
        "        hidden_1 = self.dropout(F.relu(self.conv1(x)))\n",
        "        hidden_2 = self.dropout(F.relu(self.conv2(x)))\n",
        "        hidden_3 = self.dropout(F.relu(self.conv3(x)))\n",
        "        \n",
        "        # Sum\n",
        "        hidden = hidden_1 + hidden_2 + hidden_3\n",
        "        \n",
        "        # Max pooling\n",
        "        hidden, _ = hidden.max(dim=-1)\n",
        "        \n",
        "\n",
        "        # Output layer\n",
        "        x = self.output(hidden)  # batch_size x output_size\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuaRaqdtBCrM",
        "colab_type": "text"
      },
      "source": [
        "## Build CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD95lEXmAmGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN(vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout)\n",
        "\n",
        "print(model)\n",
        "print(f'Number of parameters = {param_count(model):,}')\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWwArpwcBEeo",
        "colab_type": "text"
      },
      "source": [
        "## Train CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNN7Zrr2Ap9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    train_epoch(model, train_loader, optimizer, epoch)\n",
        "    eval_epoch(model,  dev_loader, \"Dev\")\n",
        "    print(\"---\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wROoo34BGBj",
        "colab_type": "text"
      },
      "source": [
        "## Test CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxZmibBj-GDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_epoch(model,  test_loader, \"Test\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}